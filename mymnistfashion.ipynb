{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2f100cc",
   "metadata": {
    "_cell_guid": "1e69e655-9df2-4d22-a7cd-a09bb980bfd6",
    "_uuid": "f5d576ab-4758-4d98-a12b-50fea8bac5d6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-10T14:46:28.220679Z",
     "iopub.status.busy": "2024-11-10T14:46:28.220324Z",
     "iopub.status.idle": "2024-11-10T14:46:28.916153Z",
     "shell.execute_reply": "2024-11-10T14:46:28.915125Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.702604,
     "end_time": "2024-11-10T14:46:28.918468",
     "exception": false,
     "start_time": "2024-11-10T14:46:28.215864",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fashionmnist/t10k-labels-idx1-ubyte\n",
      "/kaggle/input/fashionmnist/t10k-images-idx3-ubyte\n",
      "/kaggle/input/fashionmnist/fashion-mnist_test.csv\n",
      "/kaggle/input/fashionmnist/fashion-mnist_train.csv\n",
      "/kaggle/input/fashionmnist/train-labels-idx1-ubyte\n",
      "/kaggle/input/fashionmnist/train-images-idx3-ubyte\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9eb746",
   "metadata": {
    "_cell_guid": "48dcd746-651e-4272-88ff-04537d55f517",
    "_uuid": "2caa03b2-d14d-4795-9dca-e0b89dd269bf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-10T14:46:28.926850Z",
     "iopub.status.busy": "2024-11-10T14:46:28.926413Z",
     "iopub.status.idle": "2024-11-10T14:46:32.070426Z",
     "shell.execute_reply": "2024-11-10T14:46:32.069656Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3.151374,
     "end_time": "2024-11-10T14:46:32.073082",
     "exception": false,
     "start_time": "2024-11-10T14:46:28.921708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # First convolutional layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Second convolutional layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # Third convolutional layer\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # MaxPool layers after each convolutional layer\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 128)  # Adjusted for the new dimensions after pooling\n",
    "        self.fc2 = nn.Linear(128, 10)           # Assuming 10 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply first convolutional layer, ReLU, then MaxPool\n",
    "        x = self.pool(F.relu(self.conv1(x)))  \n",
    "        \n",
    "        # Apply second convolutional layer, ReLU, then MaxPool\n",
    "        x = self.pool(F.relu(self.conv2(x)))  \n",
    "        \n",
    "        # Apply third convolutional layer, ReLU, then MaxPool\n",
    "        x = self.pool(F.relu(self.conv3(x)))  \n",
    "        \n",
    "        # Flatten the output for the fully connected layer\n",
    "        x = x.view(-1, 128 * 3 * 3)  # Adjusted size after pooling three times\n",
    "        \n",
    "        # Apply first fully connected layer with ReLU and dropout\n",
    "        x = F.relu(self.fc1(x))  \n",
    "        \n",
    "        # Apply second fully connected layer and dropout\n",
    "        x = self.fc2(x)  \n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cd0f96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T14:46:32.080184Z",
     "iopub.status.busy": "2024-11-10T14:46:32.079764Z",
     "iopub.status.idle": "2024-11-10T14:46:34.592899Z",
     "shell.execute_reply": "2024-11-10T14:46:34.592087Z"
    },
    "papermill": {
     "duration": 2.51932,
     "end_time": "2024-11-10T14:46:34.595313",
     "exception": false,
     "start_time": "2024-11-10T14:46:32.075993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define your transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Assuming grayscale, adjust as needed\n",
    "])\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        # The data parameter here is a pandas DataFrame that already contains a split dataset\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract the label (first column) and pixel values (remaining columns)\n",
    "        label = int(self.data.iloc[idx, 0])  # Convert label to integer\n",
    "        image = self.data.iloc[idx, 1:].values.astype(np.float32)  # Pixels as float32\n",
    "        image = image.reshape(28, 28)  # Reshape to 28x28 if images are 28x28 pixels\n",
    "\n",
    "        # Convert the image to a PIL Image for the transformation\n",
    "        image = Image.fromarray(image)  # Convert to PIL Image (default mode is 'L' for grayscale)\n",
    "\n",
    "        # Apply transform (e.g., ToTensor)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7452d9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-10T14:46:34.602690Z",
     "iopub.status.busy": "2024-11-10T14:46:34.601918Z",
     "iopub.status.idle": "2024-11-10T15:05:30.863822Z",
     "shell.execute_reply": "2024-11-10T15:05:30.862816Z"
    },
    "papermill": {
     "duration": 1140.491688,
     "end_time": "2024-11-10T15:05:35.089896",
     "exception": false,
     "start_time": "2024-11-10T14:46:34.598208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/100: 100%|██████████| 1500/1500 [00:35<00:00, 42.04it/s, accuracy=79.9, loss=0.628]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.6279, Accuracy: 79.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 1/100: 100%|██████████| 375/375 [00:07<00:00, 48.12it/s, accuracy=83.5, loss=0.416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4157, Validation Accuracy: 83.51%\n",
      "Current learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.23it/s, accuracy=85.7, loss=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.3918, Accuracy: 85.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 2/100: 100%|██████████| 375/375 [00:07<00:00, 48.77it/s, accuracy=86.3, loss=0.368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3674, Validation Accuracy: 86.28%\n",
      "Current learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.43it/s, accuracy=87.1, loss=0.353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 0.3521, Accuracy: 87.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 3/100: 100%|██████████| 375/375 [00:07<00:00, 47.69it/s, accuracy=86.5, loss=0.363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3618, Validation Accuracy: 86.48%\n",
      "Current learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 4/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.24it/s, accuracy=88, loss=0.332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 0.3313, Accuracy: 88.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 4/100: 100%|██████████| 375/375 [00:07<00:00, 48.41it/s, accuracy=88.3, loss=0.332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3319, Validation Accuracy: 88.32%\n",
      "Current learning rate: 0.001000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.17it/s, accuracy=88.4, loss=0.318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.3174, Accuracy: 88.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 5/100: 100%|██████████| 375/375 [00:07<00:00, 49.49it/s, accuracy=88.1, loss=0.331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3281, Validation Accuracy: 88.11%\n",
      "Current learning rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 6/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.62it/s, accuracy=90, loss=0.273]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 0.2726, Accuracy: 90.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 6/100: 100%|██████████| 375/375 [00:07<00:00, 49.21it/s, accuracy=89.7, loss=0.28]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2779, Validation Accuracy: 89.67%\n",
      "Current learning rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 7/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.52it/s, accuracy=90.5, loss=0.258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: 0.2574, Accuracy: 90.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 7/100: 100%|██████████| 375/375 [00:07<00:00, 49.65it/s, accuracy=89.8, loss=0.281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2810, Validation Accuracy: 89.79%\n",
      "Current learning rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 8/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.46it/s, accuracy=90.8, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: 0.2485, Accuracy: 90.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 8/100: 100%|██████████| 375/375 [00:07<00:00, 49.51it/s, accuracy=89.5, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2867, Validation Accuracy: 89.50%\n",
      "Current learning rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 9/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.58it/s, accuracy=91, loss=0.245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: 0.2446, Accuracy: 90.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 9/100: 100%|██████████| 375/375 [00:07<00:00, 49.17it/s, accuracy=89.7, loss=0.287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2851, Validation Accuracy: 89.70%\n",
      "Current learning rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 10/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.32it/s, accuracy=91.2, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.2387, Accuracy: 91.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 10/100: 100%|██████████| 375/375 [00:07<00:00, 49.50it/s, accuracy=90.3, loss=0.269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2668, Validation Accuracy: 90.34%\n",
      "Current learning rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 11/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.20it/s, accuracy=92.1, loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.2128, Accuracy: 92.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 11/100: 100%|██████████| 375/375 [00:07<00:00, 49.66it/s, accuracy=90.7, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2556, Validation Accuracy: 90.67%\n",
      "Current learning rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 12/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.66it/s, accuracy=92.4, loss=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: 0.2048, Accuracy: 92.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 12/100: 100%|██████████| 375/375 [00:07<00:00, 48.69it/s, accuracy=90.8, loss=0.251]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2512, Validation Accuracy: 90.85%\n",
      "Current learning rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 13/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.35it/s, accuracy=92.6, loss=0.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: 0.2000, Accuracy: 92.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 13/100: 100%|██████████| 375/375 [00:07<00:00, 49.45it/s, accuracy=91.2, loss=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2429, Validation Accuracy: 91.17%\n",
      "Current learning rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 14/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.46it/s, accuracy=92.8, loss=0.195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: 0.1950, Accuracy: 92.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 14/100: 100%|██████████| 375/375 [00:07<00:00, 49.04it/s, accuracy=90.8, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2548, Validation Accuracy: 90.83%\n",
      "Current learning rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 15/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.78it/s, accuracy=92.9, loss=0.193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: 0.1933, Accuracy: 92.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 15/100: 100%|██████████| 375/375 [00:07<00:00, 47.63it/s, accuracy=90.9, loss=0.253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2514, Validation Accuracy: 90.92%\n",
      "Current learning rate: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 16/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.90it/s, accuracy=93.4, loss=0.179]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: 0.1781, Accuracy: 93.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 16/100: 100%|██████████| 375/375 [00:07<00:00, 48.55it/s, accuracy=91.5, loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2404, Validation Accuracy: 91.51%\n",
      "Current learning rate: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 17/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.15it/s, accuracy=93.5, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 0.1758, Accuracy: 93.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 17/100: 100%|██████████| 375/375 [00:07<00:00, 49.12it/s, accuracy=91.5, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2460, Validation Accuracy: 91.49%\n",
      "Current learning rate: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 18/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.16it/s, accuracy=93.7, loss=0.171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: 0.1706, Accuracy: 93.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 18/100: 100%|██████████| 375/375 [00:07<00:00, 48.48it/s, accuracy=91.9, loss=0.236]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2334, Validation Accuracy: 91.88%\n",
      "Current learning rate: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 19/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.64it/s, accuracy=93.8, loss=0.168]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 0.1676, Accuracy: 93.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 19/100: 100%|██████████| 375/375 [00:07<00:00, 48.88it/s, accuracy=91.3, loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2446, Validation Accuracy: 91.33%\n",
      "Current learning rate: 0.000125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 20/100: 100%|██████████| 1500/1500 [00:33<00:00, 44.13it/s, accuracy=93.9, loss=0.166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.1656, Accuracy: 93.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 20/100: 100%|██████████| 375/375 [00:08<00:00, 46.11it/s, accuracy=91.5, loss=0.241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2405, Validation Accuracy: 91.52%\n",
      "Current learning rate: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 21/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.61it/s, accuracy=94.1, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: 0.1582, Accuracy: 94.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 21/100: 100%|██████████| 375/375 [00:07<00:00, 48.03it/s, accuracy=91.6, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2434, Validation Accuracy: 91.62%\n",
      "Current learning rate: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 22/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.06it/s, accuracy=94.3, loss=0.155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: 0.1551, Accuracy: 94.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 22/100: 100%|██████████| 375/375 [00:07<00:00, 46.91it/s, accuracy=91.9, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2363, Validation Accuracy: 91.94%\n",
      "Current learning rate: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 23/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.29it/s, accuracy=94.3, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 0.1524, Accuracy: 94.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 23/100: 100%|██████████| 375/375 [00:07<00:00, 48.13it/s, accuracy=91.8, loss=0.234]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2333, Validation Accuracy: 91.76%\n",
      "Current learning rate: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 24/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.82it/s, accuracy=94.4, loss=0.152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: 0.1516, Accuracy: 94.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 24/100: 100%|██████████| 375/375 [00:07<00:00, 48.64it/s, accuracy=91.7, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2394, Validation Accuracy: 91.70%\n",
      "Current learning rate: 0.000063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 25/100: 100%|██████████| 1500/1500 [00:34<00:00, 44.05it/s, accuracy=94.4, loss=0.153]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: 0.1527, Accuracy: 94.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 25/100: 100%|██████████| 375/375 [00:07<00:00, 48.65it/s, accuracy=91.9, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2430, Validation Accuracy: 91.92%\n",
      "Current learning rate: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 26/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.85it/s, accuracy=94.7, loss=0.146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Loss: 0.1454, Accuracy: 94.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 26/100: 100%|██████████| 375/375 [00:07<00:00, 49.09it/s, accuracy=91.9, loss=0.239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2381, Validation Accuracy: 91.88%\n",
      "Current learning rate: 0.000031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 27/100: 100%|██████████| 1500/1500 [00:34<00:00, 43.97it/s, accuracy=94.7, loss=0.142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Loss: 0.1417, Accuracy: 94.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating Epoch 27/100: 100%|██████████| 375/375 [00:07<00:00, 47.89it/s, accuracy=91.9, loss=0.243]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2412, Validation Accuracy: 91.92%\n",
      "Current learning rate: 0.000031\n",
      "Early stopping triggered: No improvement in validation accuracy for 5 epochs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Import tqdm for progress bar\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Load the CSV data\n",
    "csv_file_path = '/kaggle/input/fashionmnist/fashion-mnist_train.csv'\n",
    "data = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Split the data into train and validation (80% train, 20% validation)\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Assuming you already have the test set, just load it\n",
    "test_data = pd.read_csv('/kaggle/input/fashionmnist/fashion-mnist_test.csv')\n",
    "\n",
    "# Create datasets for train, validation, and test with transform applied\n",
    "train_dataset = CustomImageDataset(data=train_data, transform=transform)\n",
    "val_dataset = CustomImageDataset(data=val_data, transform=transform)\n",
    "test_dataset = CustomImageDataset(data=test_data, transform=transform)\n",
    "\n",
    "# Create DataLoaders for each dataset\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Assuming your dataset is split into train_loader and val_loader\n",
    "# Define your model, loss function, and optimizer\n",
    "model = SimpleCNN()  # Replace with your actual model\n",
    "criterion = torch.nn.CrossEntropyLoss()  # Common loss for classification tasks\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "\n",
    "# Setup device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Early stopping parameters\n",
    "early_stopping_patience = 5  # Number of epochs to wait for improvement in validation loss\n",
    "best_val_loss = np.inf  # Start with a very large number\n",
    "best_val_accuracy = 0.0  # Start with a low validation accuracy\n",
    "epochs_without_improvement = 0  # Counter for epochs without improvement\n",
    "\n",
    "# Path to save the best model\n",
    "best_model_path = 'best_model.pth'\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 100  # Set number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap the training loop with tqdm for progress bar\n",
    "    with tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "        for inputs, labels in pbar:  # train_loader is your training DataLoader\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()  # Clear gradients\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)  # Calculate loss\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()  # Compute gradients\n",
    "            optimizer.step()  # Update model parameters\n",
    "\n",
    "            running_loss += loss.item()  # Accumulate loss for reporting\n",
    "\n",
    "            # For accuracy calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm description with current loss and accuracy\n",
    "            pbar.set_postfix(loss=running_loss / (pbar.n + 1), accuracy=100 * correct / total)\n",
    "\n",
    "    # Print the training loss and accuracy for this epoch\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation after each epoch\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap the validation loop with tqdm for progress bar\n",
    "    with tqdm(val_loader, desc=f\"Validating Epoch {epoch+1}/{num_epochs}\") as pbar:\n",
    "        with torch.no_grad():  # No gradients needed during evaluation\n",
    "            for inputs, labels in pbar:  # val_loader is your validation DataLoader\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # For accuracy calculation\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                # Update tqdm description with current validation loss and accuracy\n",
    "                pbar.set_postfix(loss=val_loss / (pbar.n + 1), accuracy=100 * correct / total)\n",
    "\n",
    "    # Print the validation loss and accuracy\n",
    "    val_loss /= len(val_loader)\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    scheduler.step()  # Adjust the learning rate based on the scheduler\n",
    "\n",
    "    # Optionally, print the current learning rate\n",
    "    print(f\"Current learning rate: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy  # Update best validation accuracy\n",
    "        torch.save(model.state_dict(), best_model_path)  # Save the model with the best accuracy\n",
    "        epochs_without_improvement = 0  # Reset counter\n",
    "    else:\n",
    "        epochs_without_improvement += 1  # Increment counter\n",
    "\n",
    "    # If no improvement for 'early_stopping_patience' epochs, stop training\n",
    "    if epochs_without_improvement >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered: No improvement in validation accuracy for 5 epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1dadf98",
   "metadata": {
    "_cell_guid": "d861301b-b27b-4641-90b6-ccb67eb1345a",
    "_uuid": "330e7024-e465-4564-9910-823c369a58ac",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-10T15:05:45.027427Z",
     "iopub.status.busy": "2024-11-10T15:05:45.026787Z",
     "iopub.status.idle": "2024-11-10T15:05:51.265122Z",
     "shell.execute_reply": "2024-11-10T15:05:51.264097Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 11.238779,
     "end_time": "2024-11-10T15:05:51.267651",
     "exception": false,
     "start_time": "2024-11-10T15:05:40.028872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 313/313 [00:06<00:00, 50.36it/s, accuracy=91.8, loss=0.238]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2353, Test Accuracy: 91.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the best model for testing with weights_only=True\n",
    "best_model = SimpleCNN()  # Initialize the model\n",
    "best_model.load_state_dict(torch.load(best_model_path, weights_only=True))  # Load only the model weights\n",
    "best_model.to(device)  # Move to the correct device\n",
    "\n",
    "\n",
    "# Testing the best model\n",
    "best_model.eval()  # Set model to evaluation mode\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# Wrap the testing loop with tqdm for progress bar\n",
    "with tqdm(test_loader, desc=\"Testing\") as pbar:\n",
    "    with torch.no_grad():  # No gradients needed during evaluation\n",
    "        for inputs, labels in pbar:  # test_loader is your test DataLoader\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = best_model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # For accuracy calculation\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            # Update tqdm description with current test loss and accuracy\n",
    "            pbar.set_postfix(loss=test_loss / (pbar.n + 1), accuracy=100 * correct / total)\n",
    "\n",
    "# Print the test results\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2243,
     "sourceId": 9243,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1172.193025,
   "end_time": "2024-11-10T15:05:57.768934",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-10T14:46:25.575909",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
